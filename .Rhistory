# Arguments:
#   alpha: alpha level for 1-alpha confidence
#   y1:     vector of scores for group 1
#   y2:     vector of scores for group 2
# Returns:
#   estimate, SE, df, t-value, p-value, lower limit, upper limit
#   for both equal variance and unequal variance methods
n1 <- length(y1)
n2 <- length(y2)
df1 <- n1 + n2 - 2
m1 <- mean(y1)
m2 <- mean(y2)
est <- m1 - m2
v1 <- var(y1)
v2 <- var(y2)
vp <- ((n1 - 1)*v1 + (n2 - 1)*v2)/df1
se1 <- sqrt(vp/n1 + vp/n2)
t1 <- est/se1
p1 <- 2*(1 - pt(abs(t1),df1))
tcrit1 <- qt(1 - alpha/2, df1)
ll1 <- est - tcrit1*se1
ul1 <- est + tcrit1*se1
se2 <- sqrt(v1/n1 + v2/n2)
t2 <- est/se2
df2 <- (se2^4)/(v1^2/(n1^3 - n1^2) + v2^2/(n2^3 - n2^2))
p2 <- 2*(1 - pt(abs(t2),df2))
tcrit2 <- qt(1 - alpha/2, df2)
ll2 <- est - tcrit2*se2
ul2 <- est + tcrit2*se2
out1 <- t(c(est, se1, t1, df1, p1, ll1, ul1))
out2 <- t(c(est, se2, t2, df2, p2, ll2, ul2))
out <- rbind(out1, out2)
colnames(out) <- c("Estimate", "SE", "t", "df", "p-value", "LL", "UL")
rownames(out) <- c("Equal Variances Assumed:", "Equal Variances Not Assumed:")
return(out)
}
ci.mean2(.05, teen1, teen2)
classroom <- c(10, 4, 7, 12, 6, 2, 15, 8, 13, 4)
studio <- c(15, 18, 9, 5, 8, 13, 14, 17, 12, 15)
ci.mean2(.05, classroom, studio)
fix(classroom)
ci.mean2(.05, classroom, studio)
fix(studio)
ci.mean2(.05, classroom, studio)
fix(studio)
ci.mean2(.05, classroom, studio)
size.ci.stdmean2 <- function(alpha, d, w, r) {
# Computes sample size required to estimate a population standardized
# mean difference with desired precision in a 2-group design.
# Arguments:
#   alpha:  alpha level for 1-alpha confidence
#   d:      planning value of standardized mean difference
#   w:      desired confidence interval width
#   r:      desired n2/n1 ratio
# Returns:
#   required sample size per group (or n1 if r not equal to 1)
z <- qnorm(1 - alpha/2)
n <- ceiling((d^2*(1 + r)/(2*r) + 4*(1 + r)/r)*(z/w)^2)
return(n)
}
size.ci.stdmean2 <- function(alpha, d, w, r) {
# Computes sample size required to estimate a population standardized
# mean difference with desired precision in a 2-group design.
# Arguments:
#   alpha:  alpha level for 1-alpha confidence
#   d:      planning value of standardized mean difference
#   w:      desired confidence interval width
#   r:      desired n2/n1 ratio
# Returns:
#   required sample size per group (or n1 if r not equal to 1)
z <- qnorm(1 - alpha/2)
n <- ceiling((d^2*(1 + r)/(2*r) + 4*(1 + r)/r)*(z/w)^2)
return(n)
}
var(classroom)
size.ci.mean2 <- function(alpha, var, w, r) {
# Computes sample size required to estimate a population mean
# difference with desired precision in a 2-group design.
# Arguments:
#   alpha:  alpha level for 1-alpha confidence
#   var:    planning value of average within-group DV variance
#   w:      desired confidence interval width
#   r:      desired n2/n1 ratio
# Returns:
#   required sample size per group (or n1 when r not equal to 1)
z <- qnorm(1 - alpha/2)
n <- ceiling(4*var*(1 + 1/r)*(z/w)^2 + z^2/4)
return(n)
}
girls <- c(16, 14, 7, 4, 19, 9, 16, 11, 13, 18, 10, 9, 15, 12, 5, 6, 2, 3, 5)
boys <- c(3, 9, 2, 5, 4, 7, 4, 3, 3, 2, 0, 1, 4, 5, 2, 1, 2, 0, 0, 4)
fix(girls)
ci.mean2(.05, girls ,boys)
var(girls)
var(boys)
mean(26.23947, 5.418421)
size.ci.mean2(.05, 15.83, 4, 1)
ci.mean2(.05, classroom, studio)
var(classroom)
var(studio)
size.ci.mean2(.05, 44.25, 5, 1)
bumped <- c(17, 8, 10, 12, 16, 14, 13)
crashed <- c(12, 22, 20, 12, 19, 18, 20)
smashed <- c(25, 26, 22, 32, 30, 22, 27)
ci.tukey.mean <-function(alpha, mean, sd, n) {
# Computes Tukey-Kramer confidence interval for all pairwise
# comparisons of means. Equal variances are not assumed.
# Arguments:
#   alpha:  alpha level for 1-alpha confidence
#   mean:   vector of sample means
#   sd:     vector of sample standard deviations
#   n:      vector of sample sizes
# Returns:
#   estimated difference, SE, test statistic, df,
#   adjusted p-value, confidence interval
a <- length(mean)
v1 <- sd^2/n
v2 <- sd^4/(n^2*(n - 1))
mean <- outer(mean, mean, '-')
diff <- mean[upper.tri(mean)]
v1 <- outer(v1, v1, "+")
v2 <- outer(v2, v2, "+")
df = v1^2/v2
df <- df[upper.tri(df)]
SE <- sqrt(v1[upper.tri(v1)])
t <- diff/SE
q <- qtukey(p = 1 - alpha, nmeans = a, df = df)/sqrt(2)
p <- 1 - ptukey(sqrt(2)*abs(t), nmeans = a, df = df)
p <- round(p*1000)/1000
LL <- diff - q*SE
UL <- diff + q*SE
pair <- t(combn(seq(1:a), 2))
out <- cbind(pair, diff, SE, t, p, df, LL, UL)
rownames(out) <- rep("", a*(a - 1)/2)
return(out)
}
mean(bumpled, crashed, smashed)
mean(bumped, crashed, smashed)
mean(bumped)
mean(crashed)
mean(smashed)
sd(bumped)
sd(crashed)
sd(smashed)
mean_vector <-c(12.85714, 17.57143, 26.28571)
sd_vector <-c(3.184785, 3.994043, 3.77334)
size_vector <-c(7, 7, 7)
ci.tukey.mean(.05, mean_vector, sd_vector, size_vector)
cumulative <-c(bumped, crashed, smashed)
n = rep(7,3)
n
group = rep(1:3, n)
group
data = data.frame(y=y, group = factor(group))
data = data.frame(y=cumulative, group = factor(group))
fit = lm(y ~ group, data)
anova (fit)
nonprofit <-c(12, 14, 9, 11, 10, 13, 8, 12, 7, 10)
practice <-c(4, 8, 7, 3, 2, 1, 2, 4, 5, 4)
research <-c(7, 9, 6, 11, 5, 8, 7, 9, 10, 6)
study_total <-c(nonprofit, practice, research)
n = rep(10, 3)
n
group = rep(1:3, n)
group
data = data.frame(y=study_total, group = factor(group))
fit = lm(y~group, data)
anova(fit)
fix(practice)
study_total <-c(nonprofit, practice, research)
data = data.frame(y=study_total, group = factor(group))
fit = lm(y~group, data)
anova(fit)
mean(nonprofit)
mean(practice)
mean(research)
sd(nonprofit)
sd(practice)
sd(research)
mean_vector_assign <-c(10.6, 3.2, 7.8)
sd_vector_assign <-c(2.221111, 1.873796, 1.932184)
size_vector_assign <-c(10, 10, 10)
ci.tukey.mean(.05, mean_vector_assign, sd_vector_assign, size_vector_assign)
contrasts(fit)
contrasts(factor(fit))
size.ci.lc.mean.bs <- function(alpha, var, w, c) {
# Computes sample size required to estimate a linear contrast of population
# mean with desired precision in a between-subjects design.
# Arguments:
#   alpha: alpha level for 1-alpha confidence
#   var:   planning value of average within-group DV variance
#   w:     desired confidence interval width
#   c:     vector of contrast coefficients
# Returns:
#   required sample size per group
z <- qnorm(1 - alpha/2)
m <- length(c) - sum(c == 0)
n <- ceiling(4*var*(t(c)%*%c)*(z/w)^2 + z^2/(2*m))
return(n)
}
contrast_coeff <-c(-1, 0, 1)
size.ci.lc.mean.bs(.05, 13.44, 5, contrast_coeff)
fix(contrast_coeff)
size.ci.lc.mean.bs(.05, 13.44, 5, contrast_coeff)
size.ci.mean2(.05, 13.44, 5, 1)
size.ci.mean2(.05, 324.90, 5, 1)
size.ci.mean2(.05, 26.89, 5, 1)
size.ci.mean2(.017, 13.44, 5, 1)
size.ci.mean2(.017, 4.059, 2, 1)
size.ci.mean2(.017, 4.059, 3, 1)
library(haven)
assignment4 <- read_sav("~/assignment4.sav")
View(assignment4)
view(direct_chat)
View(assignment4)
direct <-c(6, 6, 7, 3, 7, 4, 5, 6, 7, 7, 7, 6, 5, 4, 5, 6, 5, 6, 6, 7)
forum <-c(1,1,1,4,5,2,3,1,2,2,4,1,1,2,4,3,2,2,2,1)
small <-c(5,4,4,4,5,6,7,5,4,3,6,5,5,5,6,5,6,4,4,4)
t.test(direct, forum, paired = TRUE, alternative = "two.sided")
t.test(direct, forum, paired=T, conf.level = .983)
t.test(direct, small, paired=T, conf.level = .983)
t.test(small, forum, paired=T, conf.level = .983)
var(direct)
var(forum)
var(small)
size.ci.mean.ps <- function(alpha, var, cor, w) {
# Computes sample size required to estimate a difference in
# population means with desired precision in a paired-samples design.
# Arguments:
#   alpha:  alpha level for 1-alpha confidence
#   var:    planning value of average within-group DV variance
#   cor:    planning value of correlation
#   w:      desired confidence interval width
# Returns:
#   required sample size
z <- qnorm(1 - alpha/2)
n <- ceiling(8*(1 - cor)*var*(z/w)^2 + z^2/2)
return(n)
}
size.ci.mean.ps(.0167, 1.54, -.355, 1)
size.ci.mean.ps(.0167, 1.54, -.355, 1)
library(tidyverse)
library(tidyverse)
data <- read_csv("~/Downloads/gg_marabou_data.csv")
View(data)
View(data)
ggplot(data = data) +
geom_point(mapping = aes(x = jobs, y = runtime))
ggplot(data = data) +
geom_point(mapping = aes(x = jobs, y = runtime)) +
scale_x_continuous(trans = "log2")
ggplot(data = data) +
geom_point(mapping = aes(x = jobs, y = runtime), alpha = 0.1) +
scale_x_continuous(trans = "log2")
filter_data <- data %>% filter(grep("4_2"))
filter_data <- data %>% filter(grepl("4_2"))
filter_data <- data %>% filter(grepl("4_2", net))
View(filter_data)
View(filter_data)
ggplot(data = filter_data) +
geom_point(mapping = aes(x = jobs, y = runtime), alpha = 0.1) +
scale_x_continuous(trans = "log2")
filter_data <- data %>% filter(grepl("4_2|5_5", net))
View(filter_data)
View(filter_data)
ggplot(data = filter_data) +
geom_point(mapping = aes(x = jobs, y = runtime, color = net), alpha = 0.1) +
scale_x_continuous(trans = "log2")
ggplot(data = filter_data) +
geom_point(mapping = aes(x = jobs, y = runtime, color = net), alpha = 0.3) +
scale_x_continuous(trans = "log2")
ggplot(data = filter_data) +
geom_point(mapping = aes(x = jobs, y = runtime, color = net, shape = infra), alpha = 0.3) +
scale_x_continuous(trans = "log2")
averaged_data <- filter_data %>% group_by(jobs, net) %>% summarise(mean_runtime = mean(runtime))
View(averaged_data)
View(averaged_data)
ggplot(data = averaged_data) +
geom_point(mapping = aes(x = jobs, y = mean_runtime, color = net), alpha = 0.3) +
scale_x_continuous(trans = "log2")
ggplot(data = averaged_data) +
geom_point(mapping = aes(x = jobs, y = mean_runtime, color = net)) +
scale_x_continuous(trans = "log2")
ggplot(data = averaged_data) +
geom_point(mapping = aes(x = jobs, y = mean_runtime, color = net)) +
scale_x_continuous(trans = "log2") +
geom_line(mapping = aes(x = jobs, y = mean_runtime, color = net))
ggplot(data = averaged_data, mapping = aes(x = jobs, y = mean_runtime, color = net)) +
geom_point() +
scale_x_continuous(trans = "log2") +
geom_line()
geom_smooth()
ggplot(data = averaged_data, mapping = aes(x = jobs, y = mean_runtime, color = net)) +
geom_point() +
scale_x_continuous(trans = "log2") +
geom_line() +
geom_smooth()
tidyverse
data <- read_csv("~/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/9-25-2019/logs.csv")
import(tidyverse)
library(tidyverse)
clear
ggplot(data = averaged_data, mapping = aes(x = jobs, y = mean_runtime, color = net)) +
geom_point() +
scale_x_continuous(trans = "log2") +
geom_line() +
geom_smooth()
library(tidyverse)
data <- read_csv("/Users/verorive1/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/tim158spr19/roles.csv")
View(data)
strptime(data$createdAt)
strptime(data$createdAt, "%Y-%m-%d %H:%M:%S")
strptime(data$createdAt, "%Y-%m-%d %H:%M:%S UTC", "UTC")
strptime(data$createdAt, "%Y-%m-%d %H:%M:%S")
data$createdAt <- strptime(data$createdAt, "%Y-%m-%d %H:%M:%S")
data$updatedAt <- strptime(data$updatedAt, "%Y-%m-%d %H:%M:%S")
data$updatedAt <- strptime(data$updatedAt, "%Y-%m-%d %H:%M:%S")
data$updatedAt - data$createdAt
ggplot(data = data%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=data$updatedAt - data$createdAt))
data$duration <- data$updatedAt - data$createdAt
ggplot(data = data%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration))
ggplot(data = data%>% filter(status == "APPROVED"))
data$createdAt <- 0
data$updatedAt <- 0
ggplot(data = data%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration))
data <- read_csv("/Users/verorive1/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/tim158spr19/roles.csv")
data <- data %>% mutate(
duration = strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"),
)
help(mutate)
data <- data %>% mutate(
duration = strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration))
data <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "s"),
) %>% select(duration, status, area, u__roleTypeId)
data <- read_csv("/Users/verorive1/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/tim158spr19/roles.csv")
data <- read_csv("/Users/verorive1/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/tim158spr19/roles.csv")
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "s"),
) %>% select(duration, status, area, u__roleTypeId)
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration))
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
scale_x_continuous(trans = 'log2')
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds)) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds)) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
ta %>% mutate(
seconds =
ta %>% mutate(
seconds =
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(seconds, status, area, u__roleTypeId)
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds)) +
scale_x_continuous(trans = 'log2')
data <- read_csv("/Users/verorive1/Desktop/UCSC PhD/Social Computing/causeway-analytics/CSVs/tim158spr19/roles.csv")
data2 <- data %>% mutate(
seconds = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(seconds, status, area, u__roleTypeId)
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds)) +
scale_x_continuous(trans = 'log2')
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds, color = area)) +
scale_x_continuous(trans = 'log2')
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds, color = area)) +
facet_grid(area~u__roleTypeId)
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=seconds, color = area)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
ggplot(data = data2%>% filter(status == "APPROVED")) +
geom_histogram(aes(x=second)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "secs"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId)
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "minutes"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "mins"),
) %>% select(duration, status, area, u__roleTypeId)
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
data2 <- data %>% mutate(
duration = as.numeric(strptime(updatedAt, "%Y-%m-%d %H:%M:%S") - strptime(createdAt, "%Y-%m-%d %H:%M:%S"), units = "mins"),
)
ggplot(data = data2 %>% filter(status == "APPROVED")) +
geom_histogram(aes(x=duration)) +
facet_grid(area~u__roleTypeId) +
scale_x_continuous(trans = 'log2')
data <- read_csv("~/Downloads/most-recent-college-score-card.csv")
library(tidyverse)
data <- read_csv("~/Downloads/most-recent-college-score-card.csv")
View(data)
View(data)
View(data)
View(data)
fluidPage(
headerPanel('Iris k-means clustering'),
sidebarPanel(
selectInput('xcol', 'X Variable', names(iris)),
selectInput('ycol', 'Y Variable', names(iris),
selected = names(iris)[[2]]),
numericInput('clusters', 'Cluster count', 3,
min = 1, max = 9)
),
mainPanel(
plotOutput('plot1')
)
)
shiny::runApp('Desktop/UCSC PhD/Comprehensive Exam /shiny.rstudio.com-tutorial-master/part-1-code')
fluidPage(
headerPanel('Iris k-means clustering'),
sidebarPanel(
selectInput('xcol', 'X Variable', names(iris)),
selectInput('ycol', 'Y Variable', names(iris),
selected = names(iris)[[2]]),
numericInput('clusters', 'Cluster count', 3,
min = 1, max = 9)
),
mainPanel(
plotOutput('plot1')
)
)
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
ui <- fluidPage()
server <- function(input, output){}
shinyApp(ui = ui, server = server)
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam /shiny.rstudio.com-tutorial-master/part-1-code')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam /shiny.rstudio.com-tutorial-master/part-2-code/01-two-inputs.R')
runApp('Desktop/UCSC PhD/Comprehensive Exam /shiny.rstudio.com-tutorial-master/part-2-code/02-two-outputs.R')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
tags$h1
tags$h1()
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
shiny::runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
mydata = read.csv("scorecard-edited.csv") #read CSV file
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
mydata = read.csv("scorecard-edited.csv") #read CSV file
newdata <- na.omit(mydata)
runApp('Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData')
setwd("~/Desktop/UCSC PhD/Comprehensive Exam/CollegeScoreCardData")
mydata = read.csv("scorecard-edited.csv") #read CSV file
newdata <- na.omit(mydata)
runApp()
state = newdata %>% pull(STABBR)
print(state)
state[!duplicated(state)]
runApp()
runApp()
